{{- if .Values.autoDeploy }}
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-upgrade-job"
  labels:
    component: upgrade-job
    {{- include "dast.labels" . | nindent 4 }}
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": pre-upgrade,pre-install
    "helm.sh/hook-weight": "-10"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      name: "{{ .Release.Name }}"
      labels:
        component: upgrade-job
        {{- include "dast.labels" . | nindent 8 }}
        {{- with .Values.upgradeJob.extraPodLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      restartPolicy: Never
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccount: "{{ .Release.Name }}-upgrade-job-sa"
      initContainers:
        - name: upgrade-prep-job
          image: "{{ .Values.images.upgradeJob.repositoryKubectl }}:{{ .Values.images.upgradeJob.tagKubectl | default "latest" }}"
          imagePullPolicy: {{ .Values.images.upgradeJob.pullPolicyKubectl }}
          command:
            - sh
            - "-c"
            - |
              # Exit on any error
              set -e
              
              echo "Upgrade preparation starting..."             
              kubectl get pods -n {{ .Release.Namespace }}
              
              echo "Stopping SC DAST pods..."
              kubectl scale statefulset.apps -n {{ .Release.Namespace }} \
                -l  app.kubernetes.io/instance={{ .Release.Name }},stopBeforeUpgrade=1 --replicas=0 || true
              
              echo "Waiting for SC DAST pods to terminate..."
              kubectl wait --for=delete --timeout=90s -n {{ .Release.Namespace }} \
                -l app.kubernetes.io/instance={{ .Release.Name }},stopBeforeUpgrade=1 pod || true
              
              echo "All SC DAST pods should be terminated."
              kubectl get pods -n {{ .Release.Namespace }}
              
              echo "Upgrade preparation complete."
      containers:
        - name: upgrade-job
          image: "{{ .Values.images.upgradeJob.repository }}:{{ .Values.images.upgradeJob.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.images.upgradeJob.pullPolicy }}
          args:
            - configureEnvironment
            - --mode
            - autodeploy
            - --settingsFile
            - /app/appsettings.yaml
          env:
            - name: RELEASE_NAME
              value: {{ .Release.Name }}
            - name: SCANCENTRAL_DAST_API_SERVICE
              value: {{ include "dast-api.fullname" . }}
            - name: SCANCENTRAL_DAST_UTILITYSERVICE_SERVICE
              value: {{ include "dast-utilityservice.fullname" . }}
            - name: SCANCENTRAL_DAST_FORTIFYCONNECTSERVER_INTERNAL_SERVICE
              value: {{ include "dast-fortifyconnectserver.fullname" . }}-internal
            {{- with .Values.upgradeJob.additionalEnvironment }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          volumeMounts:
            - name: appsettings
              mountPath: /app/appsettings.yaml
              subPath: appsettings.yaml
      volumes:
        - name: appsettings
          secret:
            secretName: {{ include "secret.name" . }}
      nodeSelector:
      {{- with .Values.upgradeJob.nodeSelector }}
      {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.upgradeJob.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      tolerations:
      {{- with .Values.upgradeJob.tolerations }}
      {{- toYaml . | nindent 8 }}
      {{- end }}
  backoffLimit: 2
{{- end }}
